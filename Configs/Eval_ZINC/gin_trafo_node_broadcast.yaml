model:  ["GIN"]
batch_size: [128]
emb_dim: [256]
drop_out: [0]
num_layers: [3]
num_mlp_layers: [1]
JK: ["concat"]
pooling: ["mean"]
lr: [0.001]
graph_trafo: ["CWN"]
freeze_gnn: [0]
epochs: [1000]
drop_feat: [0]
lr_scheduler: ["ReduceLROnPlateau"]
lr_scheduler_decay_rate: [0.5]
lr_schedule_patience: [20]
min_lr: [1e-5]
node_broadcast: [1]